# aquabotBackend.py - WERSJA ZABEZPIECZONA (RODO Art. 25 Compliance)

import json
import os
import re
import hashlib
import time
import google.generativeai as genai
from flask import session, request

# Dynamiczne ≈õcie≈ºki do plik√≥w
try:
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    WATER_ANALYSIS_PATH = os.path.join(BASE_DIR, 'waterAnalysis.json')
    AVERAGES_PATH = os.path.join(BASE_DIR, 'averages.json')
except NameError:
    WATER_ANALYSIS_PATH = 'waterAnalysis.json'
    AVERAGES_PATH = 'averages.json'

try:
    # Inicjalizacja modelu Gemini
    genai.configure(api_key=os.environ.get("GOOGLE_API_KEY"))
    model = genai.GenerativeModel('gemini-2.5-flash')  # Gemini 2.5 Flash - model z wy≈ºszymi limitami
except Exception as e:
    print(f"[CRITICAL ERROR] Gemini API configuration failed: {e}")
    model = None

def parseFloat(value):
    """Helper function to parse float values, handling '<' characters."""
    if isinstance(value, str) and value.startswith('<'):
        try:
            return float(value.replace('<', '').strip())
        except (ValueError, TypeError):
            return None
    try:
        return float(value)
    except (ValueError, TypeError):
        return None

class AquaBot:
    def __init__(self):
        """Initializes the bot, loading data files as class attributes."""
        try:
            with open(WATER_ANALYSIS_PATH, 'r', encoding='utf-8') as f:
                self.full_water_data = json.load(f)
        except Exception as e:
            print(f"[ERROR] Could not load waterAnalysis.json: {e}")
            self.full_water_data = {}
        
        try:
            with open(AVERAGES_PATH, 'r', encoding='utf-8') as f:
                self.city_averages = json.load(f)
        except Exception as e:
            print(f"[ERROR] Could not load averages.json: {e}")
            self.city_averages = {}

        # MAPOWANIE NAZW
        self.param_map = {
            'twardo≈õƒá': 'twardosc', 'twardosc': 'twardosc', 'twardosci': 'twardosc',
            'azotany': 'azotany', 'azotan√≥w': 'azotany',
            '≈ºelazo': 'zelazo', 'zelaza': 'zelazo',
            'fluorki': 'fluorki', 'fluork√≥w': 'fluorki',
            'chlor': 'chlor', 'chloru': 'chlor', 'chlor wolny': 'chlor',
            'mangan': 'mangan', 'manganu': 'mangan',
            'ph': 'ph', 'odczyn': 'ph',
            'chlorki': 'chlorki', 'chlork√≥w': 'chlorki',
            'siarczany': 'siarczany', 'siarczan√≥w': 'siarczany',
            'barwa': 'barwa', 'kolor': 'barwa',
            'magnez': 'magnez',
            'potas': 'potas',
            'o≈Ç√≥w': 'olow', 'olow': 'olow',
            'rtƒôƒá': 'rtec', 'rtec': 'rtec'
        }

        # PROGI SKANKRAN
        self.thresholds = {
            'ph': {'red_low': 6.5, 'orange_low': 7.0, 'orange_high': 8.5, 'red_high': 9.5},
            'twardosc': {'red': 220, 'orange': 150},
            'azotany': {'red': 20, 'orange': 10},
            'zelazo': {'red': 0.2, 'orange': 0.1},
            'fluorki': {'red': 1.5, 'orange': 1.2},
            'chlor': {'red': 0.27, 'orange': 0.15},
            'mangan': {'red': 50, 'orange': 20},
            'chlorki': {'red': 250, 'orange': 125},
            'siarczany': {'red': 250, 'orange': 125},
            'barwa': {'red': 15, 'orange': 7.5},
            'magnez': {'red': 50, 'orange': 25},
            'potas': {'red': 12, 'orange': 6},
            'olow': {'red': 10, 'orange': 5},
            'rtec': {'red': 1, 'orange': 0.5}
        }

    def _anonymize_context(self):
        """
        Anonimizuje dane u≈ºytkownika przed wys≈Çaniem do Gemini API.
        RODO Art. 25 (Privacy by Design) - minimalizacja danych.
        """
        # Pobierz IP (obs≈Çuga proxy Nginx)
        user_ip = request.environ.get('HTTP_X_REAL_IP', 
                  request.environ.get('HTTP_X_FORWARDED_FOR', 
                  request.remote_addr))
        
        # Pobierz session_id (generowany w app.py)
        session_id = session.get('session_id', 'anonymous')
        
        # SHA256 hash - nieodwracalny (zgodno≈õƒá RODO)
        ip_hash = hashlib.sha256(user_ip.encode()).hexdigest()[:16]
        session_hash = hashlib.sha256(str(session_id).encode()).hexdigest()[:16]
        
        return {
            'ip_hash': ip_hash,
            'session_hash': session_hash,
            'timestamp': int(time.time())
        }

    def _get_color(self, parameter, value):
        """Determines the color dot based on the parameter value."""
        param_lower = parameter.lower()
        if value is None or value == "Brak danych" or value == "":
            return 'grey-dot'
        num_value = parseFloat(value)
        if num_value is None:
            return 'grey-dot'
        
        if num_value == 0:
            user_context = session.get('user_context', {})
            city_name = user_context.get('city', '')
            if city_name.lower() == 'pozna≈Ñ' and param_lower in ['olow', 'rtec']:
                return 'green-dot'
            return 'grey-dot'
        
        rules = self.thresholds.get(param_lower)
        if rules:
            if param_lower == 'ph':
                if num_value < rules['red_low'] or num_value > rules['red_high']: return 'red-dot'
                if num_value < rules['orange_low'] or num_value > rules['orange_high']: return 'orange-dot'
            else:
                if 'red' in rules and num_value > rules['red']: return 'red-dot'
                if 'orange' in rules and num_value > rules['orange']: return 'orange-dot'
        return 'green-dot'

    def _post_process_response(self, text):
        """Replaces AI tags with HTML code with colored dots."""
        def replacer(match):
            param_name = match.group(1).lower()
            value = match.group(2)
            color = self._get_color(param_name, value)
            return f'<span class="dot {color}"></span> {value}'

        pattern = re.compile(r'<param:(\w+):([^>]+)>')
        return pattern.sub(replacer, text)

    def set_station_context(self, context):
        """Sets the user context in the server-side session."""
        city_name = context.get('city')
        if city_name and self.full_water_data.get(city_name):
            session['user_context'] = context
            session['chat_history'] = []
            session.modified = True
            print(f"[DEBUG] Context set for city: {city_name}.")
        else:
            print(f"[ERROR] Data not found for city: {city_name}")

    def get_initial_greeting(self):
        """Generates the initial greeting message."""
        if 'user_context' not in session:
            return {'text_message': 'Error: Station context not set.'}

        all_params = self.get_colored_params()
        params_with_issues = [p for p in all_params if p['color'] in ['red-dot', 'orange-dot']]
        param_summary = ", ".join([f"{p['name']} ({p['value']})" for p in params_with_issues])
        if not param_summary:
            param_summary = "Wszystkie kluczowe parametry sƒÖ w normie."

        city = session['user_context']['city']
        
        # ‚úÖ ANONIMIZACJA PRZED API
        anon_context = self._anonymize_context()
        
        system_prompt = f"""Jeste≈õ AquaBotem. Przywitaj u≈ºytkownika z miasta {city}. Zwiƒô≈∫le poinformuj go o podwy≈ºszonych parametrach: {param_summary}. ZAWSZE zako≈Ñcz pytaniem: "Chcesz porozmawiaƒá o tym, jak te warto≈õci mogƒÖ wp≈Çywaƒá na Twoje zdrowie, urodƒô, czy codzienne ≈ºycie?"

[METADATA: Session={anon_context['session_hash']}, Time={anon_context['timestamp']}]
"""
        
        # Retry logic dla greeting
        max_retries = 3
        retry_delay = 1
        
        for attempt in range(max_retries):
            try:
                response = model.generate_content(system_prompt)
                bot_message = response.text
                session.setdefault('chat_history', []).append({'role': 'model', 'parts': [bot_message]})
                session.modified = True
                
                print(f"[AUDIT] AquaBot greeting sent | IP Hash: {anon_context['ip_hash']} | Session: {anon_context['session_hash']}")
                
                return {'text_message': bot_message, "parameters": params_with_issues}
            
            except Exception as e:
                error_str = str(e)
                print(f"[ERROR] Greeting API error (attempt {attempt + 1}/{max_retries}): {e}")
                
                if '429' in error_str or 'quota' in error_str.lower() or 'rate' in error_str.lower():
                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (2 ** attempt)
                        print(f"[RETRY] Rate limit hit. Waiting {wait_time}s...")
                        time.sleep(wait_time)
                        continue
                    else:
                        return {'text_message': f"Witaj w {city}! Podwy≈ºszone parametry: {param_summary}. Poczekaj chwilƒô i od≈õwie≈º stronƒô.", "parameters": params_with_issues}
                else:
                    return {'text_message': f"Witaj w {city}! Podwy≈ºszone parametry: {param_summary}. Pytaj ≈õmia≈Ço!", "parameters": params_with_issues}
        
    def get_colored_params(self):
        """Gets a list of all parameters with their colors for the current station."""
        station_data = session.get('user_context', {}).get('station', {}).get('data', {})
        params_with_colors = []
        for param, value in station_data.items():
            color = self._get_color(param, value)
            params_with_colors.append({'name': param.capitalize(), 'value': str(value), 'color': color})
        return params_with_colors

    def get_bot_response(self, user_message):
        """Generates the bot's response to a user message."""
        if not model:
            return {'text_message': "Critical Error: API Model not loaded."}
        if 'user_context' not in session:
            return {'text_message': 'Proszƒô, najpierw wybierz stacjƒô na mapie.'}

        session.setdefault('chat_history', []).append({'role': 'user', 'parts': [user_message]})
        
        city_data_for_prompt = self.full_water_data.get(session['user_context']['city'], {})
        averages_for_prompt = self.city_averages
        station_full_data = session['user_context']['station']['data']

        # ‚úÖ ANONIMIZACJA PRZED API
        anon_context = self._anonymize_context()

        system_prompt = f"""
        Jeste≈õ AquaBotem, ekspertem od jako≈õci wody i przedstawicielem misji Skankran.pl.

        --- DYREKTYWY NADRZƒòDNE ---
        1.  **"Regu≈Ça Zera"**: Warto≈õƒá '0' przy parametrze prawie zawsze oznacza 'Brak Danych'. WyjƒÖtkiem jest o≈Ç√≥w i rtƒôƒá w Poznaniu.
        2.  **"Adwokat Norm"**: Nasze progi sƒÖ surowsze ni≈º oficjalne, bo dbamy o osoby wra≈ºliwe.
        3.  **"Zwiƒôz≈Ço≈õƒá"**: M√≥w kr√≥tko i na temat.
        4.  **"Precyzja Kontekstu"**: ZAWSZE jasno okre≈õlaj, o jakich danych m√≥wisz: u≈ºywaj nazwy stacji (np. "Na stacji SUW Pi≈Çsudskiego...") lub s≈Çowa "≈õrednia" (np. "≈örednia twardo≈õƒá w Gorzowie to...").
        5.  **"Formatowanie Warto≈õci"**: Gdy w odpowiedzi podajesz warto≈õƒá liczbowƒÖ parametru, MUSISZ umie≈õciƒá jƒÖ w znacznikach <param:nazwa_parametru:warto≈õƒá>. Przyk≈Çady: "Twardo≈õƒá wynosi <param:twardosc:294>.", "Stƒô≈ºenie azotan√≥w to <param:azotany:1.1>.".
        6. **"BEZPIECZNIK MEDYCZNY" (BARDZO WA≈ªNE):**
           - NIE WOLNO Ci stawiaƒá diagnoz medycznych ani straszyƒá u≈ºytkownika bez twardych dowod√≥w.
           - Je≈õli u≈ºytkownik pyta o choroby (Crohn, rak, AZS), u≈ºywaj jƒôzyka przypuszcze≈Ñ: "Niekt√≥re badania sugerujƒÖ...", "Osoby wra≈ºliwe mogƒÖ odczuwaƒá...".
           - NIGDY nie pisz: "To pogarsza chorobƒô Crohna". Pisz: "Mo≈ºe byƒá czynnikiem dra≈ºniƒÖcym dla wra≈ºliwych jelit".
           - Przy parametrach w normie prawnej, ale powy≈ºej "naszej" normy (pomara≈Ñczowa kropka), podkre≈õlaj, ≈ºe woda JEST BEZPIECZNA wg prawa, ale my zalecamy ostro≈ºno≈õƒá dla komfortu/smaku.

        --- KONTEKST STRATEGICZNY ---
        A.  **Lokalizacja U≈ºytkownika**: Stacja {session['user_context']['station']['name']} w mie≈õcie {session['user_context']['city']}.
        B.  **Szczeg√≥≈Çowa Mapa Miasta U≈ºytkownika**: {json.dumps(city_data_for_prompt, indent=2, ensure_ascii=False)}
        C.  **PE≈ÅNE DANE TWOJEJ STACJI**: {json.dumps(station_full_data, indent=2, ensure_ascii=False)}
        D.  **Globalny Skr√≥t Wywiadowczy (≈öREDNIE)**: {json.dumps(averages_for_prompt, indent=2, ensure_ascii=False)}

        --- METADATA (Anonimizowane) ---
        [Session: {anon_context['session_hash']} | Time: {anon_context['timestamp']}]

        --- HISTORIA ROZMOWY ---
        {json.dumps(session.get('chat_history', []), indent=2, ensure_ascii=False)}
        --- KONIEC HISTORII ---

        NAJNOWSZA WIADOMO≈öCI OD U≈ªYTKOWNIKA: "{user_message}"

        TWOJE ZADANIE: Odpowiedz precyzyjnie na pytanie, bazujƒÖc na CA≈ÅYM powy≈ºszym kontek≈õcie i stosujƒÖc siƒô do Dyrektyw.
        """
        
        # Retry logic z exponential backoff dla b≈Çƒôd√≥w 429
        max_retries = 3
        retry_delay = 1  # sekunda
        
        for attempt in range(max_retries):
            try:
                chat = model.start_chat(history=session['chat_history'][:-1])
                response = chat.send_message(system_prompt)
                bot_response_text = response.text
                
                session['chat_history'].append({'role': 'model', 'parts': [bot_response_text]})
                session.modified = True
                
                processed_text = self._post_process_response(bot_response_text)
                
                print(f"[AUDIT] AquaBot response sent | IP Hash: {anon_context['ip_hash']} | Query: {user_message[:50]}...")
                
                return {'text_message': processed_text}

            except Exception as e:
                error_str = str(e)
                print(f"[ERROR] Gemini API error (attempt {attempt + 1}/{max_retries}): {e}")
                
                # Sprawd≈∫ czy to b≈ÇƒÖd 429 (rate limit)
                if '429' in error_str or 'quota' in error_str.lower() or 'rate' in error_str.lower():
                    if attempt < max_retries - 1:
                        wait_time = retry_delay * (2 ** attempt)  # Exponential backoff: 1s, 2s, 4s
                        print(f"[RETRY] Rate limit hit. Waiting {wait_time}s before retry...")
                        time.sleep(wait_time)
                        continue
                    else:
                        print(f"[ERROR] Max retries reached. Rate limit still active.")
                        session.get('chat_history', []).pop()
                        session.modified = True
                        return {'text_message': "Przepraszam, zbyt wiele zapyta≈Ñ w kr√≥tkim czasie. Poczekaj chwilƒô (ok. 1 minutƒô) i spr√≥buj ponownie. üïí"}
                else:
                    # Inny b≈ÇƒÖd - nie retry
                    session.get('chat_history', []).pop()
                    session.modified = True
                    return {'text_message': "Chwilowa awaria po≈ÇƒÖczenia z mojƒÖ inteligencjƒÖ. Spr√≥buj zadaƒá pytanie jeszcze raz!"}